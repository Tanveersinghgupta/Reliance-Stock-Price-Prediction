{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5a676688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from xgboost import plot_importance\n",
    "#ParameterGrid for Gridsearch without CV\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ebce04e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_index(inplace=True,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0abac07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data, nifty, predictions=np.array([None])):\n",
    "    \n",
    "    \"\"\"\n",
    "    The function applies future engineering to the data in order to get more information out of the inserted data. \n",
    "    The commented code below is used when we are trying to append the predictions of the model as a new input feature to train it again. In this case it performed slightli better, however depending on the parameter optimization this gain can be vanished. \n",
    "    \"\"\"\n",
    "    assert type(data) == pd.core.frame.DataFrame, \"data must be a dataframe\"\n",
    "    assert type(nifty) == pd.core.series.Series, \"SPY must be a dataframe\"\n",
    "    assert type(predictions) == np.ndarray, \"predictions must be an array\"\n",
    "       \n",
    "    if predictions.any() ==  True:\n",
    "        data = yf.download(\"RELIANCE.NS\", start=\"1990-01-01\")\n",
    "        nifty = yf.download(\"NIFTY_50\", start=\"1990-01-01\")[\"Close\"]\n",
    "        data = features(data, nifty)\n",
    "        print(data.shape)\n",
    "        data[\"Predictions\"] = predictions\n",
    "        data[\"Close\"] = data[\"Close_y\"]\n",
    "        data.drop(\"Close_y\",1,  inplace=True)\n",
    "        data.dropna(0, inplace=True)\n",
    "    else:\n",
    "        print(\"No model yet\")\n",
    "        data = features(data, nifty)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5ba0aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(data, nifty):\n",
    "    \n",
    "    for i in [2, 3, 4, 5, 6, 7]:\n",
    "                            \n",
    "        # Rolling Mean\n",
    "        data[f\"Adj_Close{i}\"] = data[\"Adj Close\"].rolling(i).mean()\n",
    "        data[f\"Volume{i}\"] = data[\"Volume\"].rolling(i).mean()\n",
    "        \n",
    "        # Rolling Standart Deviation                               \n",
    "        data[f\"Low_std{i}\"] = data[\"Low\"].rolling(i).std()\n",
    "        data[f\"High_std{i}\"] = data[\"High\"].rolling(i).std()\n",
    "        data[f\"Adj_CLose{i}\"] = data[\"Adj Close\"].rolling(i).std()\n",
    "        \n",
    "        # Stock return for the next i days\n",
    "        data[f\"Close{i}\"] = data[\"Close\"].shift(i)\n",
    "        \n",
    "        # Rolling Maximum and Minimum\n",
    "        data[f\"Adj_Close{i}\"] = data[\"Adj Close\"].rolling(i).max()\n",
    "        data[f\"Adj_Close{i}\"] = data[\"Adj Close\"].rolling(i).min()\n",
    "        \n",
    "        # Rolling Quantile\n",
    "        data[f\"Adj_Close{i}\"] = data[\"Adj Close\"].rolling(i).quantile(1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    data[\"NIFTY_50\"] =nifty\n",
    "    #Decoding the time of the year\n",
    "    data[\"Day\"] = data.index.day\n",
    "    data[\"Month\"] = data.index.month\n",
    "    data[\"Year\"] = data.index.year\n",
    "    data[\"day_year\"] = data.index.day_of_year\n",
    "    data[\"Weekday\"] = data.index.weekday\n",
    "                  \n",
    "    #Upper and Lower shade\n",
    "    data[\"Upper_Shape\"] = data[\"High\"]-np.maximum(data[\"Open\"], data[\"Close\"])\n",
    "    data[\"Lower_Shape\"] = np.minimum(data[\"Open\"], data[\"Close\"])-data[\"Low\"]\n",
    "    \n",
    "                                                                            \n",
    "    data[\"Close_y\"] = data[\"Close\"]\n",
    "    data.drop(\"Close\",1,  inplace=True)\n",
    "    data.dropna(0, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6a7c6e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowing(train, val, WINDOW, PREDICTION_SCOPE):\n",
    "    \n",
    "    \"\"\"\n",
    "    Divides the inserted data into a list of lists. Where the shape of the data becomes and additional axe, which is time.\n",
    "    Basically gets as an input shape of (X, Y) and gets returned a list which contains 3 dimensions (X, Z, Y) being Z, time.\n",
    "    \n",
    "    Input:\n",
    "        - Train Set\n",
    "        - Validation Set\n",
    "        - WINDOW: the desired window\n",
    "        - PREDICTION_SCOPE: The period in the future you want to analyze\n",
    "        \n",
    "    Output:\n",
    "        - X_train: Explanatory variables for training set\n",
    "        - y_train: Target variable training set\n",
    "        - X_test: Explanatory variables for validation set\n",
    "        - y_test:  Target variable validation set\n",
    "    \"\"\"  \n",
    "    \n",
    "    assert type(train) == np.ndarray, \"train musst be passed as an array\"\n",
    "    assert type(val) == np.ndarray, \"validation musst be passed as an array\"\n",
    "    assert type(WINDOW) == int, \"Window musst be an integer\"\n",
    "    assert type(PREDICTION_SCOPE) == int, \"Prediction scope musst be an integer\"\n",
    "    \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for i in range(len(train)-(WINDOW+PREDICTION_SCOPE)):\n",
    "        X, y = np.array(train[i:i+WINDOW, :-1]), np.array(train[i+WINDOW+PREDICTION_SCOPE, -1])\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "\n",
    "    for i in range(len(val)-(WINDOW+PREDICTION_SCOPE)):\n",
    "        X, y = np.array(val[i:i+WINDOW, :-1]), np.array(val[i+WINDOW+PREDICTION_SCOPE, -1])\n",
    "        X_test.append(X)\n",
    "        y_test.append(y)\n",
    "        \n",
    "    return X_train, y_train, X_test, y_test\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "def train_test_split(data, WINDOW):\n",
    "    \"\"\"\n",
    "    Divides the training set into train and validation set depending on the percentage indicated.\n",
    "    Note this could also be done through the sklearn traintestsplit() function.\n",
    "    \n",
    "    Input:\n",
    "        - The data to be splitted (stock data in this case)\n",
    "        - The size of the window used that will be taken as an input in order to predict the t+1\n",
    "        \n",
    "    Output:\n",
    "        - Train/Validation Set\n",
    "        - Test Set\n",
    "    \"\"\"\n",
    "    \n",
    "    assert type(data) == pd.core.frame.DataFrame, \"data musst be a dataframe\"\n",
    "    assert type(WINDOW) == int, \"Window musst be an integer\"\n",
    "    \n",
    "    train = stock_prices.iloc[:-WINDOW]\n",
    "    test = stock_prices.iloc[-WINDOW:]\n",
    "    \n",
    "    return train, test\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "def train_validation_split(train, percentage):\n",
    "    \"\"\"\n",
    "    Divides the training set into train and validation set depending on the percentage indicated\n",
    "    \"\"\"\n",
    "    assert type(train) == pd.core.frame.DataFrame, \"train musst be a dataframe\"\n",
    "    assert type(percentage) == float, \"percentage musst be a float\"\n",
    "    \n",
    "    train_set = np.array(train.iloc[:int(len(train)*percentage)])\n",
    "    validation_set = np.array(train.iloc[int(len(train)*percentage):])\n",
    "    \n",
    "    \n",
    "    return train_set, validation_set\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "def plotting(y_val, y_test, pred_test, mae, WINDOW, PREDICTION_SCOPE):\n",
    "    \n",
    "    \"\"\"This function returns a graph where:\n",
    "        - Validation Set\n",
    "        - Test Set\n",
    "        - Future Prediction\n",
    "        - Upper Bound\n",
    "        - Lower Bound\n",
    "    \"\"\"\n",
    "    assert type(WINDOW) == int, \"Window musst be an integer\"\n",
    "    assert type(PREDICTION_SCOPE) == int, \"Preiction scope musst be an integer\"\n",
    "    \n",
    "    ploting_pred = [y_test[-1], pred_test]\n",
    "    ploting_test = [y_val[-1]]+list(y_test)\n",
    "\n",
    "    time = (len(y_val)-1)+(len(ploting_test)-1)+(len(ploting_pred)-1)\n",
    "\n",
    "    test_time_init = time-(len(ploting_test)-1)-(len(ploting_pred)-1)\n",
    "    test_time_end = time-(len(ploting_pred)-1)+1\n",
    "\n",
    "    pred_time_init = time-(len(ploting_pred)-1)\n",
    "    pred_time_end = time+1\n",
    "\n",
    "    x_ticks = list(stock_prices.index[-time:])+[stock_prices.index[-1]+timedelta(PREDICTION_SCOPE+1)]\n",
    "\n",
    "    values_for_bounds = list(y_val)+list(y_test)+list(pred_test)\n",
    "    upper_band = values_for_bounds+mae\n",
    "    lower_band = values_for_bounds-mae\n",
    "    \n",
    "    print(f\"For used windowed data: {WINDOW}\")\n",
    "    print(f\"Prediction scope for date {x_ticks[-1]} / {PREDICTION_SCOPE+1} days\")\n",
    "    print(f\"The predicted price is {str(round(ploting_pred[-1][0],2))}$\")\n",
    "    print(f\"With a spread of MAE is {round(mae,2)}\")\n",
    "    print()\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    plt.plot(list(range(test_time_init, test_time_end)),ploting_test, marker=\"$m$\", color=\"orange\")\n",
    "    plt.plot(list(range(pred_time_init, pred_time_end)),ploting_pred,marker=\"$m$\", color=\"red\")\n",
    "    plt.plot(y_val, marker=\"$m$\")\n",
    "\n",
    "    plt.plot(upper_band, color=\"grey\", alpha=.3)\n",
    "    plt.plot(lower_band, color=\"grey\", alpha=.3)\n",
    "\n",
    "    plt.fill_between(list(range(0, time+1)),upper_band, lower_band, color=\"grey\", alpha=.1)\n",
    "\n",
    "    plt.xticks(list(range(0-1, time)), x_ticks, rotation=45)\n",
    "    plt.text(time-0.5, ploting_pred[-1]+2, str(round(ploting_pred[-1][0],2))+\"$\", size=11, color='red')\n",
    "    plt.title(f\"Target price for date {x_ticks[-1]} / {PREDICTION_SCOPE+1} days, with used past data of {WINDOW} days and a MAE of {round(mae,2)}\", size=15)\n",
    "    plt.legend([\"Testing Set (input for Prediction)\", \"Prediction\", \"Validation\"])\n",
    "    plt.show()\n",
    "    \n",
    "    print()\n",
    "    print(\"-----------------------------------------------------------------------------\")\n",
    "    print()\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "def inverse_transformation(X, y, y_hat):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function serves to inverse the rescaled data. \n",
    "    There are two ways in which this can happen:\n",
    "        - There could be the conversion for the validation data to see it on the plotting.\n",
    "        - There could be the conversion for the testing data, to see it plotted.\n",
    "    \"\"\"\n",
    "    assert type(X) == np.ndarray, \"X must be an array\"\n",
    "    assert type(y) == np.ndarray, \"y must be an array\"\n",
    "    \n",
    "    if X.shape[1]>1:\n",
    "        new_X = []\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            new_X.append(X[i][0])\n",
    "            \n",
    "        new_X = np.array(new_X)\n",
    "        y = np.expand_dims(y, 1)\n",
    "        \n",
    "        new_X = pd.DataFrame(new_X)\n",
    "        y = pd.DataFrame(y)\n",
    "        y_hat = pd.DataFrame(y_hat)\n",
    "\n",
    "        real_val = np.array(pd.concat((new_X, y), 1))\n",
    "        pred_val = np.array(pd.concat((new_X, y_hat), 1))\n",
    "        \n",
    "        real_val = pd.DataFrame(scaler.inverse_transform(real_val))\n",
    "        pred_val = pd.DataFrame(scaler.inverse_transform(pred_val))\n",
    "        \n",
    "    else:       \n",
    "        X = X.reshape(X.shape[0], X.shape[1]*X.shape[2])\n",
    "        \n",
    "        new_X = pd.DataFrame(X)\n",
    "        y = pd.DataFrame(y)\n",
    "        y_hat = pd.DataFrame(y_hat)\n",
    "        y_hat = pd.concat((y, y_hat))\n",
    "        y_hat.index = range(len(y_hat))\n",
    "        \n",
    "        real_val = np.array(pd.concat((new_X, y), 1))\n",
    "        pred_val = np.array(pd.concat((new_X, y_hat), 1))\n",
    "        \n",
    "        pred_val = pd.DataFrame(scaler.inverse_transform(pred_val))\n",
    "        real_val = pd.DataFrame(scaler.inverse_transform(real_val))\n",
    "        \n",
    "    return real_val, pred_val\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------------------------------------    \n",
    "def window_optimization(plots):\n",
    "    \n",
    "    \"\"\"Returns the key that contains the most optimal window (respect to mae) for t+1\"\"\"\n",
    "    \n",
    "    assert type(plots) == dict, \"plots musst be a dictionary\"\n",
    "    \n",
    "    rank = []\n",
    "    m = []\n",
    "    for i in plots.keys():\n",
    "        if not rank:\n",
    "            rank.append(plots[i])\n",
    "            m.append(i)\n",
    "        elif plots[i][3]<rank[0][3]:\n",
    "            rank.clear()\n",
    "            m.clear()\n",
    "            rank.append(plots[i])\n",
    "            m.append(i)\n",
    "            \n",
    "    return rank, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6ec4dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(mae_lstm, mae_xgboost, prediction_xgb, prediction_lstm):\n",
    "    \n",
    "    \"\"\"Returns the prediction at t+1 weighted by the respective mae. Giving a higher weight to the one which is lower\"\"\"\n",
    "    \n",
    "    prediction = (1-(mae_xgboost/(mae_lstm+mae_xgboost)))*prediction_xgb+(1-(mae_lstm/(mae_lstm+mae_xgboost)))*prediction_lstm\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0034cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_model(X_train, y_train, X_val, y_val, plotting=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Trains a preoptimized XGBoost model and returns the Mean Absolute Error an a plot if needed\n",
    "    \"\"\"     \n",
    "    xgb_model = xgb.XGBRegressor(gamma=1, n_estimators=200)\n",
    "    xgb_model.fit(X_train,y_train)\n",
    "    \n",
    "    pred_val = xgb_model.predict(X_val)\n",
    "    mae = mean_absolute_error(y_val, pred_val)\n",
    "\n",
    "    if plotting == True:\n",
    "        \n",
    "        plt.figure(figsize=(15, 6))\n",
    "        \n",
    "        sns.set_theme(style=\"white\")\n",
    "        sns.lineplot(x=range(len(y_val)), y=y_val, color=\"grey\", alpha=.4)\n",
    "        sns.lineplot(x=range(len(y_val)), y=pred_val, color=\"red\")\n",
    "\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"AAPL stock price\")\n",
    "        plt.title(f\"The MAE for this period is: {round(mae, 3)}\")\n",
    "    \n",
    "    return  mae, xgb_model\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(51)\n",
    "np.random.seed(51)\n",
    "\n",
    "def lstm_model(X_train, y_train, X_val, y_val, EPOCH,BATCH_SIZE,CALLBACK,  plotting=False):\n",
    "    \n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if (logs.get(\"val_mae\")<CALLBACK):\n",
    "                print(\"\\n Accuracy % so cancelling training\")\n",
    "                self.model.stop_training=True\n",
    "\n",
    "    callbacks = myCallback()\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.LSTM(32, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "        tf.keras.layers.LSTM(32),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "        lambda epoch: 0.228 * 10**(epoch / 20))\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.228, momentum =.85)\n",
    "    model.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer, metrics=\"mae\")\n",
    "    history = model.fit(X_train, y_train,batch_size=BATCH_SIZE, epochs=EPOCH,callbacks=[callbacks],  validation_data=[X_val, y_val], verbose=1)\n",
    "    \n",
    "    if plotting == True:\n",
    "        plt.figure(figsize=(18, 6))\n",
    "\n",
    "        lrs = 1e-5 * (10 ** (np.arange(len(history.history[\"loss\"])) / 20))\n",
    "        plt.semilogx(lrs, history.history[\"loss\"])\n",
    "        plt.xticks(size=14)\n",
    "        plt.show()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6911a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nifty_log_rets(tickers):\n",
    "    \n",
    "    \"\"\"Returns the logarithmic returns from the SP500\"\"\"\n",
    "    \n",
    "    stock_prices = yf.download(tickers, start=\"2020-01-01\", end=\"2023-11-30\")[\"Close\"]\n",
    "    log_rets = {}\n",
    "    for index, ticker in enumerate(tickers):\n",
    "        log_rets[ticker] = np.log(stock_prices[ticker]/stock_prices[ticker].shift(1))\n",
    "    return log_rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c322ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d0ddeb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "nifty = yf.download(\"^NSEI\", start='1990-01-01')[\"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "eb43433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "close = stock_prices[\"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1884c61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prices.drop(\"Close\",1, inplace=True)\n",
    "stock_prices[\"Close\"] = close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2b37a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prices.drop(\"Close\",1, inplace=True)\n",
    "stock_prices[\"Close\"] = close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "23f5bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = np.log(stock_prices[\"Close\"]/stock_prices[\"Close\"].shift(1))\n",
    "vol = np.array(stock_prices[\"2020-01-01\":\"2023-07-23\"][\"Volume\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "38c700d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6927.000000</td>\n",
       "      <td>6927.000000</td>\n",
       "      <td>6927.000000</td>\n",
       "      <td>6927.000000</td>\n",
       "      <td>6.927000e+03</td>\n",
       "      <td>6927.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>581.357172</td>\n",
       "      <td>588.240505</td>\n",
       "      <td>573.919770</td>\n",
       "      <td>561.353047</td>\n",
       "      <td>2.863630e+07</td>\n",
       "      <td>580.806892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>708.595037</td>\n",
       "      <td>715.904971</td>\n",
       "      <td>700.697336</td>\n",
       "      <td>709.632628</td>\n",
       "      <td>4.813659e+07</td>\n",
       "      <td>708.014135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.836550</td>\n",
       "      <td>11.890704</td>\n",
       "      <td>11.763055</td>\n",
       "      <td>7.827300</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>11.890704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>52.316776</td>\n",
       "      <td>53.009178</td>\n",
       "      <td>51.632114</td>\n",
       "      <td>40.832455</td>\n",
       "      <td>6.603626e+06</td>\n",
       "      <td>52.251019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>413.579681</td>\n",
       "      <td>419.473816</td>\n",
       "      <td>408.180847</td>\n",
       "      <td>382.786835</td>\n",
       "      <td>1.205621e+07</td>\n",
       "      <td>413.369171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>581.983398</td>\n",
       "      <td>599.671936</td>\n",
       "      <td>566.164581</td>\n",
       "      <td>528.668427</td>\n",
       "      <td>3.038173e+07</td>\n",
       "      <td>582.967804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2856.149902</td>\n",
       "      <td>2856.149902</td>\n",
       "      <td>2797.000000</td>\n",
       "      <td>2841.850098</td>\n",
       "      <td>6.686620e+08</td>\n",
       "      <td>2841.850098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open         High          Low    Adj Close        Volume  \\\n",
       "count  6927.000000  6927.000000  6927.000000  6927.000000  6.927000e+03   \n",
       "mean    581.357172   588.240505   573.919770   561.353047  2.863630e+07   \n",
       "std     708.595037   715.904971   700.697336   709.632628  4.813659e+07   \n",
       "min      11.836550    11.890704    11.763055     7.827300  0.000000e+00   \n",
       "25%      52.316776    53.009178    51.632114    40.832455  6.603626e+06   \n",
       "50%     413.579681   419.473816   408.180847   382.786835  1.205621e+07   \n",
       "75%     581.983398   599.671936   566.164581   528.668427  3.038173e+07   \n",
       "max    2856.149902  2856.149902  2797.000000  2841.850098  6.686620e+08   \n",
       "\n",
       "             Close  \n",
       "count  6927.000000  \n",
       "mean    580.806892  \n",
       "std     708.014135  \n",
       "min      11.890704  \n",
       "25%      52.251019  \n",
       "50%     413.369171  \n",
       "75%     582.967804  \n",
       "max    2841.850098  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_prices.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fdd28fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERCENTAGE = .995\n",
    "WINDOW = 2\n",
    "PREDICTION_SCOPE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "49cd0ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model yet\n"
     ]
    }
   ],
   "source": [
    "stock_prices = feature_engineering(stock_prices, nifty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d0631d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reg, test_reg = train_test_split(stock_prices, WINDOW)\n",
    "train_split_reg, validation_split_reg = train_validation_split(train_reg, PERCENTAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e1937101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3882, 50)\n",
      "(2, 50)\n"
     ]
    }
   ],
   "source": [
    "print(train_reg.shape)\n",
    "print(test_reg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "deda5e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj_Close2</th>\n",
       "      <th>Volume2</th>\n",
       "      <th>Low_std2</th>\n",
       "      <th>High_std2</th>\n",
       "      <th>Adj_CLose2</th>\n",
       "      <th>...</th>\n",
       "      <th>Close7</th>\n",
       "      <th>NIFTY_50</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>day_year</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Upper_Shape</th>\n",
       "      <th>Lower_Shape</th>\n",
       "      <th>Close_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-09-17</th>\n",
       "      <td>502.734589</td>\n",
       "      <td>510.015564</td>\n",
       "      <td>500.505707</td>\n",
       "      <td>450.357880</td>\n",
       "      <td>5833819</td>\n",
       "      <td>451.790039</td>\n",
       "      <td>8083104.0</td>\n",
       "      <td>1.269590</td>\n",
       "      <td>2.013856</td>\n",
       "      <td>1.012690</td>\n",
       "      <td>...</td>\n",
       "      <td>491.057770</td>\n",
       "      <td>4494.649902</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>7.280975</td>\n",
       "      <td>1.807861</td>\n",
       "      <td>502.313568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-18</th>\n",
       "      <td>500.258057</td>\n",
       "      <td>511.154755</td>\n",
       "      <td>499.242676</td>\n",
       "      <td>456.963440</td>\n",
       "      <td>10152197</td>\n",
       "      <td>456.963440</td>\n",
       "      <td>7993008.0</td>\n",
       "      <td>0.893098</td>\n",
       "      <td>0.805529</td>\n",
       "      <td>4.670836</td>\n",
       "      <td>...</td>\n",
       "      <td>486.117096</td>\n",
       "      <td>4546.200195</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>1.473511</td>\n",
       "      <td>1.015381</td>\n",
       "      <td>509.681244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-19</th>\n",
       "      <td>528.738098</td>\n",
       "      <td>540.575867</td>\n",
       "      <td>515.104797</td>\n",
       "      <td>482.686462</td>\n",
       "      <td>13357668</td>\n",
       "      <td>482.686462</td>\n",
       "      <td>11754932.5</td>\n",
       "      <td>11.216214</td>\n",
       "      <td>20.803868</td>\n",
       "      <td>18.188924</td>\n",
       "      <td>...</td>\n",
       "      <td>491.738800</td>\n",
       "      <td>4732.350098</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>262</td>\n",
       "      <td>2</td>\n",
       "      <td>2.204102</td>\n",
       "      <td>13.633301</td>\n",
       "      <td>538.371765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-20</th>\n",
       "      <td>538.891846</td>\n",
       "      <td>545.268921</td>\n",
       "      <td>536.662964</td>\n",
       "      <td>486.327881</td>\n",
       "      <td>11010710</td>\n",
       "      <td>486.327881</td>\n",
       "      <td>12184189.0</td>\n",
       "      <td>15.243926</td>\n",
       "      <td>3.318490</td>\n",
       "      <td>2.574872</td>\n",
       "      <td>...</td>\n",
       "      <td>492.853241</td>\n",
       "      <td>4747.549805</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>263</td>\n",
       "      <td>3</td>\n",
       "      <td>2.835632</td>\n",
       "      <td>2.228882</td>\n",
       "      <td>542.433289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-21</th>\n",
       "      <td>540.873047</td>\n",
       "      <td>569.353088</td>\n",
       "      <td>540.266296</td>\n",
       "      <td>506.344482</td>\n",
       "      <td>11665026</td>\n",
       "      <td>506.344482</td>\n",
       "      <td>11337868.0</td>\n",
       "      <td>2.547941</td>\n",
       "      <td>17.030078</td>\n",
       "      <td>14.153875</td>\n",
       "      <td>...</td>\n",
       "      <td>498.561646</td>\n",
       "      <td>4837.549805</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>2007</td>\n",
       "      <td>264</td>\n",
       "      <td>4</td>\n",
       "      <td>4.593933</td>\n",
       "      <td>0.606750</td>\n",
       "      <td>564.759155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-13</th>\n",
       "      <td>2783.899902</td>\n",
       "      <td>2799.000000</td>\n",
       "      <td>2737.250000</td>\n",
       "      <td>2743.000000</td>\n",
       "      <td>6776172</td>\n",
       "      <td>2767.750000</td>\n",
       "      <td>7710917.0</td>\n",
       "      <td>17.253336</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>17.500893</td>\n",
       "      <td>...</td>\n",
       "      <td>2588.750000</td>\n",
       "      <td>19413.750000</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2023</td>\n",
       "      <td>194</td>\n",
       "      <td>3</td>\n",
       "      <td>15.100098</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>2743.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-14</th>\n",
       "      <td>2750.000000</td>\n",
       "      <td>2760.899902</td>\n",
       "      <td>2725.100098</td>\n",
       "      <td>2740.699951</td>\n",
       "      <td>6979790</td>\n",
       "      <td>2743.000000</td>\n",
       "      <td>6877981.0</td>\n",
       "      <td>8.591278</td>\n",
       "      <td>26.940837</td>\n",
       "      <td>1.626380</td>\n",
       "      <td>...</td>\n",
       "      <td>2584.500000</td>\n",
       "      <td>19564.500000</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>2023</td>\n",
       "      <td>195</td>\n",
       "      <td>4</td>\n",
       "      <td>10.899902</td>\n",
       "      <td>15.599854</td>\n",
       "      <td>2740.699951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-17</th>\n",
       "      <td>2747.000000</td>\n",
       "      <td>2815.050049</td>\n",
       "      <td>2728.000000</td>\n",
       "      <td>2796.699951</td>\n",
       "      <td>10254545</td>\n",
       "      <td>2796.699951</td>\n",
       "      <td>8617167.5</td>\n",
       "      <td>2.050541</td>\n",
       "      <td>38.289936</td>\n",
       "      <td>39.597980</td>\n",
       "      <td>...</td>\n",
       "      <td>2638.750000</td>\n",
       "      <td>19711.449219</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>2023</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>18.350098</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2796.699951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-18</th>\n",
       "      <td>2817.000000</td>\n",
       "      <td>2837.449951</td>\n",
       "      <td>2793.000000</td>\n",
       "      <td>2820.449951</td>\n",
       "      <td>11937761</td>\n",
       "      <td>2820.449951</td>\n",
       "      <td>11096153.0</td>\n",
       "      <td>45.961941</td>\n",
       "      <td>15.839123</td>\n",
       "      <td>16.793786</td>\n",
       "      <td>...</td>\n",
       "      <td>2633.600098</td>\n",
       "      <td>19749.250000</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2023</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2820.449951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-19</th>\n",
       "      <td>2830.000000</td>\n",
       "      <td>2856.000000</td>\n",
       "      <td>2797.000000</td>\n",
       "      <td>2841.850098</td>\n",
       "      <td>18054869</td>\n",
       "      <td>2841.850098</td>\n",
       "      <td>14996315.0</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>13.116865</td>\n",
       "      <td>15.132189</td>\n",
       "      <td>...</td>\n",
       "      <td>2735.050049</td>\n",
       "      <td>19833.150391</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>2023</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>14.149902</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2841.850098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3882 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low    Adj Close    Volume  \\\n",
       "Date                                                                       \n",
       "2007-09-17   502.734589   510.015564   500.505707   450.357880   5833819   \n",
       "2007-09-18   500.258057   511.154755   499.242676   456.963440  10152197   \n",
       "2007-09-19   528.738098   540.575867   515.104797   482.686462  13357668   \n",
       "2007-09-20   538.891846   545.268921   536.662964   486.327881  11010710   \n",
       "2007-09-21   540.873047   569.353088   540.266296   506.344482  11665026   \n",
       "...                 ...          ...          ...          ...       ...   \n",
       "2023-07-13  2783.899902  2799.000000  2737.250000  2743.000000   6776172   \n",
       "2023-07-14  2750.000000  2760.899902  2725.100098  2740.699951   6979790   \n",
       "2023-07-17  2747.000000  2815.050049  2728.000000  2796.699951  10254545   \n",
       "2023-07-18  2817.000000  2837.449951  2793.000000  2820.449951  11937761   \n",
       "2023-07-19  2830.000000  2856.000000  2797.000000  2841.850098  18054869   \n",
       "\n",
       "             Adj_Close2     Volume2   Low_std2  High_std2  Adj_CLose2  ...  \\\n",
       "Date                                                                   ...   \n",
       "2007-09-17   451.790039   8083104.0   1.269590   2.013856    1.012690  ...   \n",
       "2007-09-18   456.963440   7993008.0   0.893098   0.805529    4.670836  ...   \n",
       "2007-09-19   482.686462  11754932.5  11.216214  20.803868   18.188924  ...   \n",
       "2007-09-20   486.327881  12184189.0  15.243926   3.318490    2.574872  ...   \n",
       "2007-09-21   506.344482  11337868.0   2.547941  17.030078   14.153875  ...   \n",
       "...                 ...         ...        ...        ...         ...  ...   \n",
       "2023-07-13  2767.750000   7710917.0  17.253336   2.121320   17.500893  ...   \n",
       "2023-07-14  2743.000000   6877981.0   8.591278  26.940837    1.626380  ...   \n",
       "2023-07-17  2796.699951   8617167.5   2.050541  38.289936   39.597980  ...   \n",
       "2023-07-18  2820.449951  11096153.0  45.961941  15.839123   16.793786  ...   \n",
       "2023-07-19  2841.850098  14996315.0   2.828427  13.116865   15.132189  ...   \n",
       "\n",
       "                 Close7      NIFTY_50  Day  Month  Year  day_year  Weekday  \\\n",
       "Date                                                                         \n",
       "2007-09-17   491.057770   4494.649902   17      9  2007       260        0   \n",
       "2007-09-18   486.117096   4546.200195   18      9  2007       261        1   \n",
       "2007-09-19   491.738800   4732.350098   19      9  2007       262        2   \n",
       "2007-09-20   492.853241   4747.549805   20      9  2007       263        3   \n",
       "2007-09-21   498.561646   4837.549805   21      9  2007       264        4   \n",
       "...                 ...           ...  ...    ...   ...       ...      ...   \n",
       "2023-07-13  2588.750000  19413.750000   13      7  2023       194        3   \n",
       "2023-07-14  2584.500000  19564.500000   14      7  2023       195        4   \n",
       "2023-07-17  2638.750000  19711.449219   17      7  2023       198        0   \n",
       "2023-07-18  2633.600098  19749.250000   18      7  2023       199        1   \n",
       "2023-07-19  2735.050049  19833.150391   19      7  2023       200        2   \n",
       "\n",
       "            Upper_Shape  Lower_Shape      Close_y  \n",
       "Date                                               \n",
       "2007-09-17     7.280975     1.807861   502.313568  \n",
       "2007-09-18     1.473511     1.015381   509.681244  \n",
       "2007-09-19     2.204102    13.633301   538.371765  \n",
       "2007-09-20     2.835632     2.228882   542.433289  \n",
       "2007-09-21     4.593933     0.606750   564.759155  \n",
       "...                 ...          ...          ...  \n",
       "2023-07-13    15.100098     5.750000  2743.000000  \n",
       "2023-07-14    10.899902    15.599854  2740.699951  \n",
       "2023-07-17    18.350098    19.000000  2796.699951  \n",
       "2023-07-18    17.000000    24.000000  2820.449951  \n",
       "2023-07-19    14.149902    33.000000  2841.850098  \n",
       "\n",
       "[3882 rows x 50 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb5938b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e1cd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e7a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
